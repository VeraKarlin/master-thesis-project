{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.labels = pd.read_csv(csv_file).iloc[:]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature_path = os.path.join(self.root_dir, self.labels.iloc[idx,0])\n",
    "        embeddings = torch.load(feature_path)\n",
    "        features = embeddings[:, :, :768]\n",
    "        maps = embeddings[:, :, 768:]\n",
    "        rmsds = [float(label) for label in literal_eval(self.labels.iloc[idx, 1])]\n",
    "        if self.transform:\n",
    "            embedding = self.transform(embedding)\n",
    "        return features, maps, rmsds, feature_path\n",
    "    \n",
    "dataset = Dataset(csv_file='/home/vera/projects/masters_project/data/rmsd_dataset.csv',\n",
    "                                    root_dir='/home/vera/projects/masters_project/data/s-pred_features/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8304 1038 1038\n",
      "torch.Size([1, 1, 164, 768])\n",
      "torch.Size([1, 1, 164, 288])\n",
      "164\n",
      "('/home/vera/projects/masters_project/data/s-pred_features/embeddings_5cuh_a.pt',)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train, validation and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "# Test if the dataset is split correctly\n",
    "print(len(train_dataset), len(valid_dataset), len(test_dataset))\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 1 \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Test if the dataloaders are working correctly\n",
    "for i, (features, maps, rmsds, feature_path) in enumerate(train_loader):\n",
    "    print(features.shape)\n",
    "    print(maps.shape)\n",
    "    print(len(rmsds))\n",
    "    print(feature_path)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Sort the data by length of the embeddings\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_dataset \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(train_dataset, key\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: x[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], reverse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Go through the data and create batches of embeddings with the same length\u001b[39;00m\n\u001b[1;32m      6\u001b[0m train_batches \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     12\u001b[0m     feature_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39miloc[idx,\u001b[39m0\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m     embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(feature_path)\n\u001b[1;32m     14\u001b[0m     features \u001b[39m=\u001b[39m embeddings[:, :, :\u001b[39m768\u001b[39m]\n\u001b[1;32m     15\u001b[0m     maps \u001b[39m=\u001b[39m embeddings[:, :, \u001b[39m768\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:811\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    810\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 811\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    812\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    813\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:1174\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1172\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1173\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1174\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1176\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1178\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:1144\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1143\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1144\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1146\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:1118\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1114\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[1;32m   1115\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1118\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1119\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1120\u001b[0m     _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1122\u001b[0m \u001b[39mif\u001b[39;00m typed_storage\u001b[39m.\u001b[39m_data_ptr() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1123\u001b[0m     loaded_storages[key] \u001b[39m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:219\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    218\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 219\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    220\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:184\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    183\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 184\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    185\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    186\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:167\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_cuda_device\u001b[39m(location):\n\u001b[1;32m    165\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mis_available():\n\u001b[1;32m    168\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    171\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    172\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    173\u001b[0m     device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/cuda/__init__.py:116\u001b[0m, in \u001b[0;36mis_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m device_count() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[39m# The default availability inspection never throws and returns 0 if the driver is missing or can't\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39m# be initialized. This uses the CUDA Runtime API `cudaGetDeviceCount` which in turn initializes the CUDA Driver\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39m# API via `cuInit`\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_getDeviceCount() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "# Sort the data by length of the embeddings\n",
    "train_dataset = sorted(train_dataset, key=lambda x: x[0].shape[1], reverse=True)\n",
    "\n",
    "# Go through the data and create batches of embeddings with the same length\n",
    "train_batches = []\n",
    "\n",
    "for i in range(0, len(train_dataset), batch_size):\n",
    "    batch = train_dataset[i:i+batch_size]\n",
    "    # Check if all embeddings in the batch have the same length\n",
    "    if len(set([embedding[0].shape[1] for embedding in batch])) != 1:\n",
    "        continue\n",
    "    train_batches.append(batch)\n",
    "# Shuffle the batches\n",
    "random.shuffle(train_batches)\n",
    "\n",
    "# Test if the batches are created correctly\n",
    "for i, batch in enumerate(train_batches):\n",
    "    print('Batch ' + str(i))\n",
    "    for features, maps, rmsds, feature_path in batch:\n",
    "        print(features.shape)\n",
    "        print(maps.shape)\n",
    "        print(len(rmsds))\n",
    "        print(feature_path)\n",
    "    break\n",
    "\n",
    "# Create data loaders for the batches\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_batches)\n",
    "\n",
    "# Test if the dataloaders are working correctly\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print('Batch ' + str(i))\n",
    "    for features, maps, rmsds, feature_path in batch:\n",
    "        print(features.shape)\n",
    "        print(maps.shape)\n",
    "        print(len(rmsds))\n",
    "        print(feature_path)\n",
    "    break\n",
    "\n",
    "print(len(train_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM model\n",
    "class lstm_net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_feature_size=768, hidden_node=256, dropout=0.25, class_num=8):\n",
    "        super(lstm_net, self).__init__()\n",
    "\n",
    "        self.linear_proj = nn.Sequential(\n",
    "            nn.Linear(input_feature_size, input_feature_size // 2),\n",
    "            nn.InstanceNorm1d(input_feature_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_feature_size // 2, input_feature_size // 4),\n",
    "            nn.InstanceNorm1d(input_feature_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_feature_size // 4, input_feature_size // 4),\n",
    "        )\n",
    "\n",
    "        lstm_input_feature_size = input_feature_size // 4 + 144*2\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_feature_size,\n",
    "            hidden_size=hidden_node,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.to_property = nn.Sequential(\n",
    "            nn.Linear(hidden_node * 2, hidden_node * 2),\n",
    "            nn.InstanceNorm1d(hidden_node * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_node * 2, class_num),\n",
    "        )\n",
    "\n",
    "    def forward(self, msa_query_embeddings, msa_attention_features):\n",
    "        msa_query_embeddings = self.linear_proj(msa_query_embeddings)\n",
    "\n",
    "        lstm_input = torch.cat([msa_query_embeddings, msa_attention_features], dim=2)\n",
    "        lstm_input = lstm_input.permute((1, 0, 2))\n",
    "\n",
    "        lstm_output, lstm_hidden = self.lstm(lstm_input)\n",
    "        lstm_output = lstm_output.permute((1, 0, 2))\n",
    "        \n",
    "        label_output = self.to_property(lstm_output)\n",
    "\n",
    "        return label_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m valid_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m i, (features, maps, rmsds, feature_path) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m---> 36\u001b[0m     features \u001b[39m=\u001b[39m features[\u001b[39m0\u001b[39;49m,:,:,:]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m     maps \u001b[39m=\u001b[39m maps[\u001b[39m0\u001b[39m,:,:,:]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     38\u001b[0m     labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39mint\u001b[39m(label \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m RMSD_THRESHOLD) \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m rmsds])\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0\n",
    "BATCH_SIZE = 1\n",
    "HIDDEN_NODE = 256\n",
    "DROPOUT = 0\n",
    "CLASS_NUM = 1\n",
    "NUM_ACCUMULATION_STEPS = 2\n",
    "\n",
    "RMSD_THRESHOLD = 1\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "model = lstm_net(input_feature_size=768, hidden_node=HIDDEN_NODE, dropout=DROPOUT, class_num=CLASS_NUM)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.zero_grad()\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "\n",
    "    for i, (features, maps, rmsds, feature_path) in enumerate(train_loader):\n",
    "        features = features[0,:,:,:].to(device)\n",
    "        maps = maps[0,:,:,:].to(device)\n",
    "        labels = torch.Tensor([int(label >= RMSD_THRESHOLD) for label in rmsds]).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(msa_query_embeddings=features, msa_attention_features=maps)\n",
    "        loss = criterion(output[0,:,0], labels)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss_list.append(train_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (features, maps, rmsds, feature_path) in enumerate(valid_loader):\n",
    "            features = features[0,:,:,:].to(device)\n",
    "            maps = maps[0,:,:,:].to(device)\n",
    "            labels = torch.Tensor([int(label >= RMSD_THRESHOLD) for label in rmsds]).to(device)\n",
    "\n",
    "            output = model(msa_query_embeddings=features, msa_attention_features=maps)\n",
    "            loss = criterion(output[0,:,0], labels)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "        valid_loss_list.append(valid_loss / len(valid_loader))\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss_list[-1], valid_loss_list[-1]))\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SE3-nvidia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
