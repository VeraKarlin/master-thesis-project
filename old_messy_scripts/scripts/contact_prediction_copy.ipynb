{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980cdce5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b89ecde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fe9d1243c70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple, Optional, Dict, NamedTuple, Union, Callable\n",
    "import itertools\n",
    "import os\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import squareform, pdist, cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from Bio import SeqIO\n",
    "import biotite.structure as bs\n",
    "from biotite.structure.io.pdbx import PDBxFile, get_structure\n",
    "from biotite.database import rcsb\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import esm\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4715a68",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d471e2",
   "metadata": {},
   "source": [
    "## Parsing alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f0be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an efficient way to delete lowercase characters and insertion characters from a string\n",
    "deletekeys = dict.fromkeys(string.ascii_lowercase)\n",
    "deletekeys[\".\"] = None\n",
    "deletekeys[\"*\"] = None\n",
    "translation = str.maketrans(deletekeys)\n",
    "\n",
    "def read_sequence(filename: str) -> Tuple[str, str]:\n",
    "    \"\"\" Reads the first (reference) sequences from a fasta or MSA file.\"\"\"\n",
    "    record = next(SeqIO.parse(filename, \"fasta\"))\n",
    "    return record.description, str(record.seq)\n",
    "\n",
    "def remove_insertions(sequence: str) -> str:\n",
    "    \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n",
    "    return sequence.translate(translation)\n",
    "\n",
    "def read_msa(filename: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\" Reads the sequences from an MSA file, automatically removes insertions.\"\"\"\n",
    "    return [(record.description, remove_insertions(str(record.seq))) for record in SeqIO.parse(filename, \"fasta\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5716f5dc",
   "metadata": {},
   "source": [
    "## Converting structures to contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2265de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend(a, b, c, L, A, D):\n",
    "    \"\"\"\n",
    "    input:  3 coords (a,b,c), (L)ength, (A)ngle, and (D)ihedral\n",
    "    output: 4th coord\n",
    "    \"\"\"\n",
    "\n",
    "    def normalize(x):\n",
    "        return x / np.linalg.norm(x, ord=2, axis=-1, keepdims=True)\n",
    "\n",
    "    bc = normalize(b - c)\n",
    "    n = normalize(np.cross(b - a, bc))\n",
    "    m = [bc, np.cross(n, bc), n]\n",
    "    d = [L * np.cos(A), L * np.sin(A) * np.cos(D), -L * np.sin(A) * np.sin(D)]\n",
    "    return c + sum([m * d for m, d in zip(m, d)])\n",
    "\n",
    "\n",
    "def contacts_from_pdb(\n",
    "    structure: bs.AtomArray,\n",
    "    distance_threshold: float = 8.0,\n",
    "    chain: Optional[str] = None,\n",
    ") -> np.ndarray:\n",
    "    mask = ~structure.hetero\n",
    "    if chain is not None:\n",
    "        mask &= structure.chain_id == chain\n",
    "\n",
    "    N = structure.coord[mask & (structure.atom_name == \"N\")]\n",
    "    CA = structure.coord[mask & (structure.atom_name == \"CA\")]\n",
    "    C = structure.coord[mask & (structure.atom_name == \"C\")]\n",
    "\n",
    "    Cbeta = extend(C, N, CA, 1.522, 1.927, -2.143)\n",
    "    dist = squareform(pdist(Cbeta))\n",
    "    \n",
    "    contacts = dist < distance_threshold\n",
    "    contacts = contacts.astype(np.int64)\n",
    "    contacts[np.isnan(dist)] = -1\n",
    "    return contacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15136469",
   "metadata": {},
   "source": [
    "## Subsampling MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc16df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sequences from the MSA to maximize the hamming distance\n",
    "# Alternatively, can use hhfilter \n",
    "def greedy_select(msa: List[Tuple[str, str]], num_seqs: int, mode: str = \"max\") -> List[Tuple[str, str]]:\n",
    "    assert mode in (\"max\", \"min\")\n",
    "    if len(msa) <= num_seqs:\n",
    "        return msa\n",
    "    \n",
    "    array = np.array([list(seq) for _, seq in msa], dtype=np.bytes_).view(np.uint8)\n",
    "\n",
    "    optfunc = np.argmax if mode == \"max\" else np.argmin\n",
    "    all_indices = np.arange(len(msa))\n",
    "    indices = [0]\n",
    "    pairwise_distances = np.zeros((0, len(msa)))\n",
    "    for _ in range(num_seqs - 1):\n",
    "        dist = cdist(array[indices[-1:]], array, \"hamming\")\n",
    "        pairwise_distances = np.concatenate([pairwise_distances, dist])\n",
    "        shifted_distance = np.delete(pairwise_distances, indices, axis=1).mean(0)\n",
    "        shifted_index = optfunc(shifted_distance)\n",
    "        index = np.delete(all_indices, indices)[shifted_index]\n",
    "        indices.append(index)\n",
    "    indices = sorted(indices)\n",
    "    return [msa[idx] for idx in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9cd36",
   "metadata": {},
   "source": [
    "## Compute contact precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6397673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precisions(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    src_lengths: Optional[torch.Tensor] = None,\n",
    "    minsep: int = 6,\n",
    "    maxsep: Optional[int] = None,\n",
    "    override_length: Optional[int] = None,  # for casp\n",
    "):\n",
    "    if isinstance(predictions, np.ndarray):\n",
    "        predictions = torch.from_numpy(predictions)\n",
    "    if isinstance(targets, np.ndarray):\n",
    "        targets = torch.from_numpy(targets)\n",
    "    if predictions.dim() == 2:\n",
    "        predictions = predictions.unsqueeze(0)\n",
    "    if targets.dim() == 2:\n",
    "        targets = targets.unsqueeze(0)\n",
    "    override_length = (targets[0, 0] >= 0).sum()\n",
    "\n",
    "    # Check sizes\n",
    "    if predictions.size() != targets.size():\n",
    "        raise ValueError(\n",
    "            f\"Size mismatch. Received predictions of size {predictions.size()}, \"\n",
    "            f\"targets of size {targets.size()}\"\n",
    "        )\n",
    "    device = predictions.device\n",
    "\n",
    "    batch_size, seqlen, _ = predictions.size()\n",
    "    seqlen_range = torch.arange(seqlen, device=device)\n",
    "\n",
    "    sep = seqlen_range.unsqueeze(0) - seqlen_range.unsqueeze(1)\n",
    "    sep = sep.unsqueeze(0)\n",
    "    valid_mask = sep >= minsep\n",
    "    valid_mask = valid_mask & (targets >= 0)  # negative targets are invalid\n",
    "\n",
    "    if maxsep is not None:\n",
    "        valid_mask &= sep < maxsep\n",
    "\n",
    "    if src_lengths is not None:\n",
    "        valid = seqlen_range.unsqueeze(0) < src_lengths.unsqueeze(1)\n",
    "        valid_mask &= valid.unsqueeze(1) & valid.unsqueeze(2)\n",
    "    else:\n",
    "        src_lengths = torch.full([batch_size], seqlen, device=device, dtype=torch.long)\n",
    "\n",
    "    predictions = predictions.masked_fill(~valid_mask, float(\"-inf\"))\n",
    "\n",
    "    x_ind, y_ind = np.triu_indices(seqlen, minsep)\n",
    "    predictions_upper = predictions[:, x_ind, y_ind]\n",
    "    targets_upper = targets[:, x_ind, y_ind]\n",
    "\n",
    "    topk = seqlen if override_length is None else max(seqlen, override_length)\n",
    "    indices = predictions_upper.argsort(dim=-1, descending=True)[:, :topk]\n",
    "    topk_targets = targets_upper[torch.arange(batch_size).unsqueeze(1), indices]\n",
    "    if topk_targets.size(1) < topk:\n",
    "        topk_targets = F.pad(topk_targets, [0, topk - topk_targets.size(1)])\n",
    "\n",
    "    cumulative_dist = topk_targets.type_as(predictions).cumsum(-1)\n",
    "\n",
    "    gather_lengths = src_lengths.unsqueeze(1)\n",
    "    if override_length is not None:\n",
    "        gather_lengths = override_length * torch.ones_like(\n",
    "            gather_lengths, device=device\n",
    "        )\n",
    "\n",
    "    gather_indices = (\n",
    "        torch.arange(0.1, 1.1, 0.1, device=device).unsqueeze(0) * gather_lengths\n",
    "    ).type(torch.long) - 1\n",
    "\n",
    "    binned_cumulative_dist = cumulative_dist.gather(1, gather_indices)\n",
    "    binned_precisions = binned_cumulative_dist / (gather_indices + 1).type_as(\n",
    "        binned_cumulative_dist\n",
    "    )\n",
    "\n",
    "    pl5 = binned_precisions[:, 1]\n",
    "    pl2 = binned_precisions[:, 4]\n",
    "    pl = binned_precisions[:, 9]\n",
    "    auc = binned_precisions.mean(-1)\n",
    "\n",
    "    return {\"AUC\": auc, \"P@L\": pl, \"P@L2\": pl2, \"P@L5\": pl5}\n",
    "\n",
    "\n",
    "def evaluate_prediction(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    ") -> Dict[str, float]:\n",
    "    if isinstance(targets, np.ndarray):\n",
    "        targets = torch.from_numpy(targets)\n",
    "    contact_ranges = [\n",
    "        (\"local\", 3, 6),\n",
    "        (\"short\", 6, 12),\n",
    "        (\"medium\", 12, 24),\n",
    "        (\"long\", 24, None),\n",
    "    ]\n",
    "    metrics = {}\n",
    "    targets = targets.to(predictions.device)\n",
    "    for name, minsep, maxsep in contact_ranges:\n",
    "        rangemetrics = compute_precisions(\n",
    "            predictions,\n",
    "            targets,\n",
    "            minsep=minsep,\n",
    "            maxsep=maxsep,\n",
    "        )\n",
    "        for key, val in rangemetrics.items():\n",
    "            metrics[f\"{name}_{key}\"] = val.item()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac461070",
   "metadata": {},
   "source": [
    "## Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdcf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adapted from: https://github.com/rmrao/evo/blob/main/evo/visualize.py\"\"\"\n",
    "def plot_contacts_and_predictions(\n",
    "    predictions: Union[torch.Tensor, np.ndarray],\n",
    "    contacts: Union[torch.Tensor, np.ndarray],\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    # artists: Optional[ContactAndPredictionArtists] = None,\n",
    "    cmap: str = \"Blues\",\n",
    "    ms: float = 1,\n",
    "    title: Union[bool, str, Callable[[float], str]] = True,\n",
    "    animated: bool = False,\n",
    ") -> None:\n",
    "\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "    if isinstance(contacts, torch.Tensor):\n",
    "        contacts = contacts.detach().cpu().numpy()\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    seqlen = contacts.shape[0]\n",
    "    relative_distance = np.add.outer(-np.arange(seqlen), np.arange(seqlen))\n",
    "    bottom_mask = relative_distance < 0\n",
    "    masked_image = np.ma.masked_where(bottom_mask, predictions)\n",
    "    invalid_mask = np.abs(np.add.outer(np.arange(seqlen), -np.arange(seqlen))) < 6\n",
    "    predictions = predictions.copy()\n",
    "    predictions[invalid_mask] = float(\"-inf\")\n",
    "\n",
    "    topl_val = np.sort(predictions.reshape(-1))[-seqlen]\n",
    "    pred_contacts = predictions >= topl_val\n",
    "    true_positives = contacts & pred_contacts & ~bottom_mask\n",
    "    false_positives = ~contacts & pred_contacts & ~bottom_mask\n",
    "    other_contacts = contacts & ~pred_contacts & ~bottom_mask\n",
    "\n",
    "    if isinstance(title, str):\n",
    "        title_text: Optional[str] = title\n",
    "    elif title:\n",
    "        long_range_pl = compute_precisions(predictions, contacts, minsep=24)[\n",
    "            \"P@L\"\n",
    "        ].item()\n",
    "        if callable(title):\n",
    "            title_text = title(long_range_pl)\n",
    "        else:\n",
    "            title_text = f\"Long Range P@L: {100 * long_range_pl:0.1f}\"\n",
    "    else:\n",
    "        title_text = None\n",
    "\n",
    "    img = ax.imshow(masked_image, cmap=cmap, animated=animated)\n",
    "    oc = ax.plot(*np.where(other_contacts), \"o\", c=\"grey\", ms=ms)[0]\n",
    "    fn = ax.plot(*np.where(false_positives), \"o\", c=\"r\", ms=ms)[0]\n",
    "    tp = ax.plot(*np.where(true_positives), \"o\", c=\"b\", ms=ms)[0]\n",
    "    ti = ax.set_title(title_text) if title_text is not None else None\n",
    "    # artists = ContactAndPredictionArtists(img, oc, fn, tp, ti)\n",
    "\n",
    "    ax.axis(\"square\")\n",
    "    ax.set_xlim([0, seqlen])\n",
    "    ax.set_ylim([0, seqlen])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d20a52",
   "metadata": {},
   "source": [
    "# Predict and Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37bc3a3",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b80820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where the data is actually read in\n",
    "PDB_IDS = [\"1a3a\", \"5ahw\", \"1xcr\"]\n",
    "\n",
    "structures = {\n",
    "    name.lower(): get_structure(PDBxFile.read(rcsb.fetch(name, \"cif\")))[0]\n",
    "    for name in PDB_IDS\n",
    "}\n",
    "\n",
    "contacts = {\n",
    "    name: contacts_from_pdb(structure, chain=\"A\") \n",
    "    for name, structure in structures.items()\n",
    "}\n",
    "\n",
    "msas = {\n",
    "    name: read_msa(f\"data/{name.lower()}_1_A.a3m\")\n",
    "    for name in PDB_IDS\n",
    "}\n",
    "\n",
    "sequences = {\n",
    "    name: msa[0] for name, msa in msas.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd2845",
   "metadata": {},
   "source": [
    "## ESM-2 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a219b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "esm2, esm2_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "esm2 = esm2.eval().cuda()\n",
    "esm2_batch_converter = esm2_alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746fa0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "esm2_predictions = {}\n",
    "esm2_results = []\n",
    "for name, inputs in sequences.items():\n",
    "    esm2_batch_labels, esm2_batch_strs, esm2_batch_tokens = esm2_batch_converter([inputs])\n",
    "    esm2_batch_tokens = esm2_batch_tokens.to(next(esm2.parameters()).device)\n",
    "    esm2_predictions[name] = esm2.predict_contacts(esm2_batch_tokens)[0].cpu()\n",
    "    metrics = {\"id\": name, \"model\": \"ESM-2 (Unsupervised)\"}\n",
    "    metrics.update(evaluate_prediction(esm2_predictions[name], contacts[name]))\n",
    "    esm2_results.append(metrics)\n",
    "esm2_results = pd.DataFrame(esm2_results)\n",
    "display(esm2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7783907",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(18, 6), ncols=3)\n",
    "for ax, name in zip(axes, PDB_IDS):\n",
    "    prediction = esm2_predictions[name]\n",
    "    target = contacts[name]\n",
    "    plot_contacts_and_predictions(\n",
    "        prediction, target, ax=ax, title = lambda prec: f\"{name}: Long Range P@L: {100 * prec:0.1f}\"\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9129eb3",
   "metadata": {},
   "source": [
    "## MSA Transformer Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedc64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_transformer, msa_transformer_alphabet = esm.pretrained.esm_msa1b_t12_100M_UR50S()\n",
    "msa_transformer = msa_transformer.eval().cuda()\n",
    "msa_transformer_batch_converter = msa_transformer_alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedfc650",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_transformer_predictions = {}\n",
    "msa_transformer_results = []\n",
    "for name, inputs in msas.items():\n",
    "    inputs = greedy_select(inputs, num_seqs=128) # can change this to pass more/fewer sequences\n",
    "    msa_transformer_batch_labels, msa_transformer_batch_strs, msa_transformer_batch_tokens = msa_transformer_batch_converter([inputs])\n",
    "    msa_transformer_batch_tokens = msa_transformer_batch_tokens.to(next(msa_transformer.parameters()).device)\n",
    "    msa_transformer_predictions[name] = msa_transformer.predict_contacts(msa_transformer_batch_tokens)[0].cpu()\n",
    "    metrics = {\"id\": name, \"model\": \"MSA Transformer (Unsupervised)\"}\n",
    "    metrics.update(evaluate_prediction(msa_transformer_predictions[name], contacts[name]))\n",
    "    msa_transformer_results.append(metrics)\n",
    "msa_transformer_results = pd.DataFrame(msa_transformer_results)\n",
    "display(msa_transformer_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3571ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(18, 6), ncols=3)\n",
    "for ax, name in zip(axes, PDB_IDS):\n",
    "    prediction = msa_transformer_predictions[name]\n",
    "    target = contacts[name]\n",
    "    plot_contacts_and_predictions(\n",
    "        prediction, target, ax=ax, title = lambda prec: f\"{name}: Long Range P@L: {100 * prec:0.1f}\"\n",
    "    )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
