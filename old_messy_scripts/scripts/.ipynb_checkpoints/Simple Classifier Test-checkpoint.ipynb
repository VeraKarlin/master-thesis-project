{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, transforms\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cluster_rmsds_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10403\n"
     ]
    }
   ],
   "source": [
    "dir_path = '/mnt/nasdata/vera/msa_transformer_embeddings/*'\n",
    "embedding_files = {file_name.split('/')[-1] for file_name in glob.glob(dir_path)}\n",
    "data = {}\n",
    "for index, row in df.iterrows():\n",
    "    rmsd_list = [row[5:5+int(row['length'])].values.tolist()]\n",
    "    pdb_id = row['pdb_id']\n",
    "    embedding_file = 'embeddings_' + pdb_id[:4] + '_' + pdb_id[4].lower() + '.pt'\n",
    "    if embedding_file in embedding_files:\n",
    "        data[embedding_file] = rmsd_list\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsd_dataset = pd.DataFrame.from_dict(data, orient='index')\n",
    "rmsd_dataset.to_csv('../data/rmsd_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.labels = pd.read_csv(csv_file).sample(100)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        embedding_path = os.path.join(self.root_dir, self.labels.iloc[idx,0])\n",
    "        embedding = torch.load(embedding_path)\n",
    "        label = literal_eval(self.labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            embedding = self.transform(embedding)\n",
    "        return embedding, label, embedding_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SmallDataset(csv_file='../data/rmsd_dataset.csv',\n",
    "                                    root_dir='/mnt/nasdata/vera/msa_transformer_embeddings/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([209, 768])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[25][0][0][:][1][:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = test_dataset[23][0][0,:,1,:].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA class\n",
    "pca = PCA(n_components=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform feature set\n",
    "new_feature_set = pca.fit_transform(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 16)\n"
     ]
    }
   ],
   "source": [
    "print(new_feature_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.451086  ,  4.957172  ,  1.2965112 , ...,  2.123791  ,\n",
       "        -1.2510049 ,  1.1796682 ],\n",
       "       [ 1.2180768 ,  2.2817183 ,  0.42695534, ...,  0.43066245,\n",
       "         1.4244059 , -0.11070893],\n",
       "       [ 5.4178905 ,  3.094024  , -0.93604875, ..., -0.75943094,\n",
       "        -0.13720031,  1.4712237 ],\n",
       "       ...,\n",
       "       [ 1.6147488 , -3.0943813 ,  1.1871496 , ...,  0.590542  ,\n",
       "         2.2659724 ,  1.325006  ],\n",
       "       [-0.26194412, -2.5441074 ,  0.2858513 , ..., -0.6241302 ,\n",
       "        -0.12774006,  0.34780914],\n",
       "       [-0.49971464, -1.0685382 , -0.09630635, ..., -0.4897208 ,\n",
       "         0.61182183,  0.6384848 ]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleResidueDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        sequence_labels = pd.read_csv(csv_file).sample(100).iloc[:][1]\n",
    "        all_labels = itertools.chain(sequence_labels.tolist())\n",
    "        self.labels = all_labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        embedding_path = os.path.join(self.root_dir, self.labels.iloc[idx,0])\n",
    "        embedding = torch.load(embedding_path)\n",
    "        label = literal_eval(self.labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            embedding = self.transform(embedding)\n",
    "        return embedding, label, embedding_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 108527616])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv('../data/rmsd_dataset.csv').sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22115"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = []\n",
    "for seq in df4.iloc[:,1].tolist():\n",
    "    all_labels += literal_eval(seq)\n",
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "5908480\n"
     ]
    }
   ],
   "source": [
    "root_dir='/mnt/nasdata/vera/msa_transformer_embeddings/'\n",
    "all_embeddings = []\n",
    "for i in range(50):\n",
    "    embedding, labels, path = test_dataset[i]\n",
    "    for residue in range(embedding.shape[2]-1):\n",
    "        small_embedding = pca.fit_transform(embedding[0,:,residue+1,:].cpu().numpy())\n",
    "        all_embeddings += torch.from_numpy(small_embedding)\n",
    "    print(i)\n",
    "print(len(all_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_model():\n",
    "    gc.collect()\n",
    "    all_embeddings = []\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv('../data/rmsd_dataset.csv').sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir='/mnt/nasdata/vera/msa_transformer_embeddings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 305, 768])\n",
      "4l00_b\n",
      "torch.Size([1, 512, 232, 768])\n",
      "6gqf_a\n",
      "torch.Size([1, 512, 142, 768])\n",
      "5z1t_a\n",
      "torch.Size([1, 512, 157, 768])\n",
      "3ljl_a\n",
      "torch.Size([1, 512, 148, 768])\n",
      "6gxg_b\n",
      "torch.Size([1, 512, 336, 768])\n",
      "2zbw_b\n",
      "torch.Size([1, 512, 267, 768])\n",
      "4hqo_b\n",
      "torch.Size([1, 512, 210, 768])\n",
      "1zgl_u\n",
      "torch.Size([1, 512, 165, 768])\n",
      "3pu2_b\n",
      "torch.Size([1, 512, 308, 768])\n",
      "4n7w_a\n",
      "torch.Size([1, 512, 328, 768])\n",
      "5z75_a\n",
      "torch.Size([1, 512, 323, 768])\n",
      "4z90_a\n",
      "torch.Size([1, 512, 266, 768])\n",
      "5lk5_a\n",
      "torch.Size([1, 512, 228, 768])\n",
      "6o3l_h\n",
      "torch.Size([1, 512, 251, 768])\n",
      "4iqz_a\n",
      "torch.Size([1, 512, 291, 768])\n",
      "3c18_a\n",
      "torch.Size([1, 512, 281, 768])\n",
      "4c16_a\n",
      "torch.Size([1, 512, 139, 768])\n",
      "6a6f_a\n",
      "torch.Size([1, 512, 209, 768])\n",
      "4qtu_b\n",
      "torch.Size([1, 512, 287, 768])\n",
      "1jr2_a\n",
      "torch.Size([1, 512, 232, 768])\n",
      "6bft_a\n",
      "torch.Size([1, 512, 187, 768])\n",
      "5cdj_b\n",
      "torch.Size([1, 512, 126, 768])\n",
      "2cxy_a\n",
      "torch.Size([1, 512, 140, 768])\n",
      "6kta_a\n",
      "torch.Size([1, 512, 390, 768])\n",
      "6ny5_a\n",
      "torch.Size([1, 512, 302, 768])\n",
      "4kwv_f\n",
      "torch.Size([1, 512, 354, 768])\n",
      "5m71_a\n",
      "torch.Size([1, 512, 263, 768])\n",
      "4uv3_a\n",
      "torch.Size([1, 512, 289, 768])\n",
      "6rf0_c\n",
      "torch.Size([1, 512, 401, 768])\n",
      "5ahm_a\n",
      "torch.Size([1, 512, 208, 768])\n",
      "6cgu_a\n",
      "torch.Size([1, 512, 353, 768])\n",
      "4e84_a\n",
      "torch.Size([1, 512, 347, 768])\n",
      "4fif_a\n",
      "torch.Size([1, 512, 146, 768])\n",
      "2fe3_b\n",
      "torch.Size([1, 512, 303, 768])\n",
      "4ngd_a\n",
      "torch.Size([1, 512, 268, 768])\n",
      "3no4_a\n",
      "torch.Size([1, 512, 160, 768])\n",
      "1h88_c\n",
      "torch.Size([1, 512, 389, 768])\n",
      "1jll_b\n",
      "torch.Size([1, 512, 127, 768])\n",
      "5hem_a\n",
      "torch.Size([1, 512, 104, 768])\n",
      "2zzs_a\n",
      "torch.Size([1, 512, 208, 768])\n",
      "5cj0_a\n",
      "torch.Size([1, 512, 216, 768])\n",
      "5xt2_b\n",
      "torch.Size([1, 512, 223, 768])\n",
      "2nyv_a\n",
      "torch.Size([1, 512, 112, 768])\n",
      "5t9p_c\n",
      "torch.Size([1, 512, 192, 768])\n",
      "1i5d_a\n",
      "torch.Size([1, 512, 103, 768])\n",
      "2h9u_a\n",
      "torch.Size([1, 512, 337, 768])\n",
      "3h4j_b\n",
      "torch.Size([1, 512, 149, 768])\n",
      "3f6r_a\n",
      "torch.Size([1, 512, 126, 768])\n",
      "1gyb_a\n",
      "torch.Size([1, 512, 393, 768])\n",
      "3n4f_a\n",
      "torch.Size([1, 512, 362, 768])\n",
      "6imc_d\n",
      "torch.Size([1, 512, 141, 768])\n",
      "5b3d_b\n",
      "torch.Size([1, 512, 395, 768])\n",
      "5yiy_a\n",
      "torch.Size([1, 512, 215, 768])\n",
      "6uta_l\n",
      "torch.Size([1, 512, 373, 768])\n",
      "3jze_a\n",
      "torch.Size([1, 512, 141, 768])\n",
      "5lyp_a\n",
      "torch.Size([1, 512, 320, 768])\n",
      "6ahy_b\n",
      "torch.Size([1, 512, 226, 768])\n",
      "3wkm_h\n",
      "torch.Size([1, 512, 240, 768])\n",
      "4e41_j\n",
      "torch.Size([1, 512, 272, 768])\n",
      "2w96_a\n",
      "torch.Size([1, 512, 207, 768])\n",
      "1rkv_a\n",
      "torch.Size([1, 512, 325, 768])\n",
      "1tnd_a\n",
      "torch.Size([1, 512, 264, 768])\n",
      "5h28_a\n",
      "torch.Size([1, 512, 112, 768])\n",
      "5e50_a\n",
      "torch.Size([1, 512, 112, 768])\n",
      "3mlf_a\n",
      "torch.Size([1, 512, 148, 768])\n",
      "3dmb_a\n",
      "torch.Size([1, 512, 172, 768])\n",
      "3icl_a\n",
      "torch.Size([1, 512, 137, 768])\n",
      "5elr_d\n",
      "torch.Size([1, 512, 287, 768])\n",
      "6mps_a\n",
      "torch.Size([1, 512, 386, 768])\n",
      "1x86_a\n",
      "torch.Size([1, 512, 307, 768])\n",
      "4p0q_a\n",
      "torch.Size([1, 512, 362, 768])\n",
      "5jk7_c\n",
      "torch.Size([1, 512, 221, 768])\n",
      "6c30_a\n",
      "torch.Size([1, 512, 195, 768])\n",
      "3dpj_a\n",
      "torch.Size([1, 512, 182, 768])\n",
      "5mq8_a\n",
      "torch.Size([1, 512, 231, 768])\n",
      "6n7j_a\n",
      "torch.Size([1, 512, 382, 768])\n",
      "2q99_a\n",
      "torch.Size([1, 512, 120, 768])\n",
      "2cz4_a\n",
      "torch.Size([1, 512, 356, 768])\n",
      "6gup_a\n",
      "torch.Size([1, 512, 229, 768])\n",
      "4hps_a\n",
      "torch.Size([1, 512, 99, 768])\n",
      "5vsu_b\n",
      "torch.Size([1, 512, 352, 768])\n",
      "3g3e_a\n",
      "torch.Size([1, 512, 323, 768])\n",
      "3b39_a\n",
      "torch.Size([1, 512, 100, 768])\n",
      "1zyr_e\n",
      "torch.Size([1, 512, 230, 768])\n",
      "4m7k_h\n",
      "torch.Size([1, 512, 227, 768])\n",
      "4afs_a\n",
      "torch.Size([1, 512, 235, 768])\n",
      "5br9_c\n",
      "torch.Size([1, 512, 137, 768])\n",
      "3siq_a\n",
      "torch.Size([1, 512, 302, 768])\n",
      "5igh_a\n",
      "torch.Size([1, 512, 65, 768])\n",
      "2f60_k\n",
      "torch.Size([1, 512, 231, 768])\n",
      "1mj8_h\n",
      "torch.Size([1, 512, 132, 768])\n",
      "2cjt_c\n",
      "torch.Size([1, 512, 214, 768])\n",
      "1z3g_l\n",
      "torch.Size([1, 512, 281, 768])\n",
      "4ijz_b\n",
      "torch.Size([1, 512, 317, 768])\n",
      "1esm_a\n",
      "torch.Size([1, 512, 69, 768])\n",
      "3o27_a\n",
      "torch.Size([1, 512, 353, 768])\n",
      "4y2h_b\n",
      "torch.Size([1, 512, 92, 768])\n",
      "1d3b_l\n",
      "torch.Size([1, 512, 92, 768])\n",
      "4n6x_a\n",
      "torch.Size([1, 512, 141, 768])\n",
      "6uht_d\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for index, row in df4.iterrows():\n",
    "    embedding_path = os.path.join(root_dir, row[0])\n",
    "    embeddings = torch.load(embedding_path)\n",
    "    pdb_id = row[0].replace('embeddings_', '').replace('.pt', '')\n",
    "    print(embeddings.shape)\n",
    "    print(pdb_id)\n",
    "    continue\n",
    "    for residue in range(embeddings.shape[2]-1):\n",
    "        test_dataset[23][0][0,:,1,:].cpu().numpy()\n",
    "        residue_embeddings = embeddings[:,:,residue+1,:]\n",
    "        print(residue_embeddings.shape)\n",
    "        #output_path = \"../data/100_embeddings/\" + pdb_id + '_' + str(residue) + '.pt'\n",
    "        #torch.save(residue_embeddings, output_path)\n",
    "    i += 1\n",
    "    if i == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime;\n",
    "import time\n",
    "ct = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/nasdata/vera/msa_transformer_embeddings/embeddings_6pon_b.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9751322269439697\n"
     ]
    }
   ],
   "source": [
    "ts1 = time.time()\n",
    "tensor = torch.load(path)\n",
    "ts2 = time.time()\n",
    "print(ts2 - ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = pd.read_csv('../data/rmsd_dataset.csv').sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_3m3w_b.pt 320 0.18 –> 0.55 ms/residue\n",
      "embeddings_2hzk_d.pt 365 0.2 –> 0.54 ms/residue\n",
      "embeddings_5ans_a.pt 175 0.1 –> 0.57 ms/residue\n",
      "embeddings_2c35_b.pt 172 0.1 –> 0.56 ms/residue\n",
      "embeddings_5lp5_c.pt 248 0.14 –> 0.55 ms/residue\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    pdb_id = df_names.iloc[i,0]\n",
    "    length = len(literal_eval(df_names.iloc[i,1]))\n",
    "    ts1 = time.time()\n",
    "    tensor = torch.load('/mnt/nasdata/vera/msa_transformer_embeddings/' + pdb_id)\n",
    "    ts2 = time.time()\n",
    "    diff = ts2 - ts1\n",
    "    print(pdb_id, length, round(diff, 2), '–>', round(1000*diff/length, 2), 'ms/residue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17844319343566895\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ts1 = time.time()\n",
    "tensor = torch.load('/home/vera/projects/masters_project/data/100_embeddings/4bkm_a_23.pt')\n",
    "ts2 = time.time()\n",
    "diff = ts2 - ts1\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2348949909210205\n",
      "7.745619297027588\n",
      "7.0855584144592285\n",
      "9.984408378601074\n",
      "9.019051790237427\n"
     ]
    }
   ],
   "source": [
    "for pdb_path in glob.glob('/home/vera/projects/masters_project/data/100_embeddings/6aae_b_*'):\n",
    "    tensor = torch.load(pdb_path)\n",
    "    ts1 = time.time()\n",
    "    torch.save(tensor, pdb_path)\n",
    "    ts2 = time.time()\n",
    "    diff = ts2 - ts1\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
