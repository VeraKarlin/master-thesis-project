{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#\n",
    "# Arontier Inc.: Artificial Intelligence in Precision Medicine\n",
    "# Copyright: 2018-present\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import esm\n",
    "import json\n",
    "import numpy as np\n",
    "import argparse\n",
    "from einops import rearrange\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f17506a5e80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROTEIN_PROPERTY = \"disorder\"\n",
    "DISORDER_LABEL = '+'\n",
    "\n",
    "MAX_MSA_ROW_NUM = 256  # 256\n",
    "MAX_MSA_COL_NUM = 1023  # start token +1 1024\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_net(nn.Module):\n",
    "    def __init__(self, input_feature_size=768, hidden_node=256, dropout=0.25, need_row_attention=False, class_num=8):\n",
    "        super().__init__()\n",
    "        self.need_row_attention = need_row_attention\n",
    "        self.linear_proj = nn.Sequential(\n",
    "            nn.Linear(input_feature_size, input_feature_size // 2),\n",
    "            nn.InstanceNorm1d(input_feature_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_feature_size // 2, input_feature_size // 4),\n",
    "            nn.InstanceNorm1d(input_feature_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_feature_size // 4, input_feature_size // 4),\n",
    "        )\n",
    "\n",
    "        if self.need_row_attention:\n",
    "            lstm_input_feature_size = input_feature_size // 4 + 144*2\n",
    "        else:\n",
    "            lstm_input_feature_size = input_feature_size // 4\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_feature_size,\n",
    "            hidden_size=hidden_node,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        self.to_property = nn.Sequential(\n",
    "            nn.Linear(hidden_node * 2, hidden_node * 2),\n",
    "            nn.InstanceNorm1d(hidden_node * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_node * 2, class_num),\n",
    "        )\n",
    "\n",
    "    def forward(self, msa_query_embeddings, msa_row_attentions):\n",
    "        msa_query_embeddings = self.linear_proj(msa_query_embeddings)\n",
    "\n",
    "        if self.need_row_attention:\n",
    "            msa_row_attentions = rearrange(msa_row_attentions, 'b l h i j -> b (l h) i j')\n",
    "            msa_attention_features = torch.cat((torch.mean(msa_row_attentions, dim=2), torch.mean(msa_row_attentions, dim=3)), dim=1)\n",
    "            # msa_attention_features = (torch.mean(msa_row_attentions, dim=2) + torch.mean(msa_row_attentions, dim=3))/2\n",
    "            msa_attention_features = msa_attention_features.permute((0, 2, 1))\n",
    "\n",
    "            lstm_input = torch.cat([msa_query_embeddings, msa_attention_features], dim=2)\n",
    "\n",
    "        else:\n",
    "            lstm_input = msa_query_embeddings\n",
    "\n",
    "        lstm_input = lstm_input.permute((1, 0, 2))\n",
    "        lstm_output, lstm_hidden = self.lstm(lstm_input)\n",
    "        lstm_output = lstm_output.permute((1, 0, 2))\n",
    "        label_output = self.to_property(lstm_output)\n",
    "\n",
    "        return label_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_msa_transformer_features(msa_seq, msa_transformer, msa_batch_converter, device=torch.device(\"cpu\")):\n",
    "    msa_seq_label, msa_seq_str, msa_seq_token = msa_batch_converter([msa_seq])\n",
    "    msa_seq_token = msa_seq_token.to(device)\n",
    "    msa_row, msa_col = msa_seq_token.shape[1], msa_seq_token.shape[2]\n",
    "    print(f\"{msa_seq_label[0][0]}, msa_row: {msa_row}, msa_col: {msa_col}\")\n",
    "\n",
    "    if msa_col > MAX_MSA_COL_NUM:\n",
    "        print(f\"msa col num should less than {MAX_MSA_COL_NUM}. This program force the msa col to under {MAX_MSA_COL_NUM}\")\n",
    "    msa_seq_token = msa_seq_token[:, :, :MAX_MSA_COL_NUM]\n",
    "\n",
    "    ### keys: ['logits', 'representations', 'col_attentions', 'row_attentions', 'contacts']\n",
    "    msa_transformer_outputs = msa_transformer(\n",
    "        msa_seq_token, repr_layers=[12],\n",
    "        need_head_weights=True, return_contacts=True)\n",
    "    msa_row_attentions = msa_transformer_outputs['row_attentions']\n",
    "    msa_representations = msa_transformer_outputs['representations'][12]\n",
    "    msa_query_representation = msa_representations[:, 0, 1:, :]  # remove start token\n",
    "    msa_row_attentions = msa_row_attentions[..., 1:, 1:]  # remove start token\n",
    "\n",
    "    return msa_query_representation, msa_row_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_find_ch(s, ch):\n",
    "    return [i for i, ltr in enumerate(s) if ltr == ch]\n",
    "\n",
    "\n",
    "\n",
    "def save_property_to_json(out_property_json, output_property, query_seq):\n",
    "    output_property_list = output_property.tolist()\n",
    "    output_property_list = [round(x, 4) for x in output_property_list]\n",
    "\n",
    "    json_dict = {\n",
    "        \"disorder_data\": output_property_list,\n",
    "        \"query_seq\": query_seq,\n",
    "        \"metadata\": {\n",
    "            \"precision\": 4,\n",
    "            \"title\": \"disorder\",\n",
    "            \"data-min\": 0,\n",
    "            \"data-max\": 1,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(out_property_json, \"w\") as f:\n",
    "        json.dump(json_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='S-Pred for accessible surface area prediction: input msa and output idr (.json)')\n",
    "    parser.add_argument('-i', '--input_path', type=str, default='examples/s_pred_idr.a3m',\n",
    "                        help='input msa path (.json or .a3m)')\n",
    "    parser.add_argument('-o', '--output_path', type=str, default='s_pred_idr.out',\n",
    "                        help='output predicted idr probability')\n",
    "    parser.add_argument('--conv_model_path', type=str,\n",
    "                        default='s_pred_idr_weights.pth',\n",
    "                        help='model weight path')\n",
    "\n",
    "    msa_args = parser.add_argument_group('MSA')\n",
    "\n",
    "    msa_args.add_argument('--msa_method', type=str, help='input msa method')\n",
    "    msa_args.add_argument('--msa_row_num', type=int, default=256,\n",
    "                          help='input msa row num to msa transformer')\n",
    "    parser.add_argument('--device', type=str, default='cpu', choices=['cpu', 'gpu'],\n",
    "                        help='choose device: cpu or gpu')\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"===================================\")\n",
    "    print(\"Print Arguments:\")\n",
    "    print(\"===================================\")\n",
    "\n",
    "    print(' '.join(f'{k} = {v}\\n' for k, v in vars(args).items()))\n",
    "\n",
    "\n",
    "    if args.device == 'cpu':\n",
    "        device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda:0\")\n",
    "        else:\n",
    "            print(\"gpu is not available, run on cpu\")\n",
    "            device = torch.device(\"cpu\")\n",
    "\n",
    "    ## if already have the msa_transformer_weight\n",
    "    ## msa_transformer, msa_alphabet = esm.pretrained.load_model_and_alphabet_local(msa_transformer_weight_path)\n",
    "\n",
    "    msa_transformer, msa_alphabet = esm.pretrained.esm_msa1_t12_100M_UR50S()\n",
    "    msa_batch_converter = msa_alphabet.get_batch_converter()\n",
    "\n",
    "    msa_transformer.to(device)\n",
    "    msa_transformer.eval()\n",
    "\n",
    "    conv_model = lstm_net(input_feature_size=768, hidden_node=256, dropout=0.25, need_row_attention=True, class_num=1)\n",
    "    conv_model = conv_model.to(device)\n",
    "\n",
    "    if device.type == 'cpu':\n",
    "        ch = torch.load(args.conv_model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        ch = torch.load(args.conv_model_path)\n",
    "\n",
    "    conv_model.load_state_dict(ch['conv_model'])\n",
    "    conv_model.to(device)\n",
    "    conv_model.eval()\n",
    "\n",
    "    for param in msa_transformer.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in conv_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    print(\"===================================\")\n",
    "    print(\"Extract msa transformer features\")\n",
    "    print(\"===================================\")\n",
    "\n",
    "    if args.input_path.endswith('.json'):\n",
    "        msa_seq, query_seq = read_msa_json(args.input_path, args.msa_method, args.msa_row_num)\n",
    "    else:\n",
    "        msa_seq, query_seq = read_msa_file(args.input_path, args.msa_row_num)\n",
    "\n",
    "\n",
    "    msa_row_num = len(msa_seq)\n",
    "    msa_col_num = len(query_seq)\n",
    "\n",
    "    print(f\"msa row number: {msa_row_num}\")\n",
    "    print(f\"msa column number: {msa_col_num}\")\n",
    "\n",
    "\n",
    "    msa_query_representation, msa_row_attentions = extract_msa_transformer_features(msa_seq,\n",
    "                                                                                    msa_transformer,\n",
    "                                                                                    msa_batch_converter,\n",
    "                                                                                    device=device)\n",
    "\n",
    "    msa_query_representation.to(device)\n",
    "    msa_row_attentions.to(device)\n",
    "\n",
    "    output_property = conv_model(msa_query_representation, msa_row_attentions)\n",
    "\n",
    "    output_property_sigmoid = F.sigmoid(output_property)\n",
    "    output_property_sigmoid_np = output_property_sigmoid.data.cpu().numpy().squeeze()\n",
    "\n",
    "    output_property_json_path = args.output_path + '.idr.json'\n",
    "    save_property_to_json(output_property_json_path, output_property_sigmoid_np, query_seq)\n",
    "\n",
    "    print(\"===================================\")\n",
    "    print(\"Done\")\n",
    "    print(\"===================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SE3-nvidia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
