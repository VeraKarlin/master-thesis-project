{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os\n",
      "glob\n",
      "torch\n",
      "nn\n",
      "F\n",
      "optim\n",
      "Dataset\n",
      "DataLoader\n",
      "literal_eval\n",
      "pd\n",
      "np\n",
      "plt\n",
      "itertools\n",
      "random\n",
      "Variable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"os\")\n",
    "import glob\n",
    "print(\"glob\")\n",
    "import torch\n",
    "print(\"torch\")\n",
    "from torch import nn\n",
    "print(\"nn\")\n",
    "import torch.nn.functional as F\n",
    "print(\"F\")\n",
    "import torch.optim as optim\n",
    "print(\"optim\")\n",
    "from torch.utils.data import Dataset\n",
    "print(\"Dataset\")\n",
    "from torch.utils.data import DataLoader\n",
    "print(\"DataLoader\")\n",
    "from ast import literal_eval\n",
    "print(\"literal_eval\")\n",
    "import pandas as pd\n",
    "print(\"pd\")\n",
    "import numpy as np\n",
    "print(\"np\")\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"plt\")\n",
    "import itertools\n",
    "print(\"itertools\")\n",
    "import random\n",
    "print(\"random\")\n",
    "from torch.autograd import Variable\n",
    "print(\"Variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        # Only select the first 2000 rows for now\n",
    "        self.labels = pd.read_csv(csv_file).iloc[:]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature_path = os.path.join(self.root_dir, self.labels.iloc[idx,0])\n",
    "        embeddings = torch.load(feature_path)\n",
    "        features = embeddings[:, :, :768]\n",
    "        maps = embeddings[:, :, 768:]\n",
    "        rmsds = [float(label) for label in literal_eval(self.labels.iloc[idx, 1])]\n",
    "        if self.transform:\n",
    "            embedding = self.transform(embedding)\n",
    "        return features, maps, rmsds, feature_path\n",
    "    \n",
    "dataset = Dataset(csv_file='/home/vera/projects/masters_project/data/rmsd_dataset.csv',\n",
    "                                    root_dir='/home/vera/projects/masters_project/data/s-pred_features/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    csv_file_df = pd.read_csv('/home/vera/projects/masters_project/data/rmsd_dataset.csv')\n",
    "\n",
    "    # Test if the labels have the sane length as the embeddings\n",
    "    for i in range(len(dataset)):\n",
    "        features, maps, rmsds, feature_path = dataset[i]\n",
    "        if features.shape[1] != len(rmsds):\n",
    "            print('ERROR: The embedding and label for \"' + feature_path + '\" have different lengths!')\n",
    "            print('Embedding length: ' + str(features.shape[1]))\n",
    "            print('Label length: ' + str(len(rmsds)))\n",
    "\n",
    "            csv_file_df.drop(csv_file_df[csv_file_df['Unnamed: 0'] == feature_path.split('/')[-1]].index, inplace=True)\n",
    "\n",
    "    # Save the new csv file\n",
    "    csv_file_df.to_csv('/home/vera/projects/masters_project/data/rmsd_dataset.csv', index=False)\n",
    "\n",
    "print('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0627,  0.4644,  0.3815,  ..., -0.2154, -0.4263, -0.8542],\n",
       "          [-0.2771, -0.5295,  0.3261,  ..., -0.5385,  0.6916, -0.0551],\n",
       "          [-0.6896, -0.8251,  0.2244,  ..., -0.6500,  0.4918, -0.6983],\n",
       "          ...,\n",
       "          [-0.6249, -1.5928, -0.3101,  ..., -1.4699, -0.1669, -1.6153],\n",
       "          [-0.9852, -0.8269,  0.4922,  ..., -0.5268,  0.0339, -1.4123],\n",
       "          [-0.7165, -0.3634,  0.1148,  ..., -0.0383,  0.6593, -0.9017]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[0.0021, 0.0031, 0.0012,  ..., 0.0023, 0.0022, 0.0028],\n",
       "          [0.0024, 0.0024, 0.0031,  ..., 0.0026, 0.0026, 0.0028],\n",
       "          [0.0022, 0.0029, 0.0031,  ..., 0.0027, 0.0028, 0.0029],\n",
       "          ...,\n",
       "          [0.0015, 0.0030, 0.0047,  ..., 0.0026, 0.0026, 0.0029],\n",
       "          [0.0011, 0.0038, 0.0029,  ..., 0.0027, 0.0025, 0.0029],\n",
       "          [0.0010, 0.0017, 0.0016,  ..., 0.0023, 0.0021, 0.0027]]],\n",
       "        device='cuda:0'),\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.02,\n",
       "  0.109,\n",
       "  0.154,\n",
       "  1.496,\n",
       "  1.546,\n",
       "  1.588,\n",
       "  1.581,\n",
       "  1.586,\n",
       "  1.547,\n",
       "  1.354,\n",
       "  1.126,\n",
       "  1.137,\n",
       "  1.133,\n",
       "  1.061,\n",
       "  1.041,\n",
       "  0.971,\n",
       "  0.376,\n",
       "  0.339,\n",
       "  0.28,\n",
       "  0.275,\n",
       "  0.264,\n",
       "  0.264,\n",
       "  0.363,\n",
       "  0.44,\n",
       "  0.477,\n",
       "  0.464,\n",
       "  0.56,\n",
       "  0.774,\n",
       "  0.724,\n",
       "  0.791,\n",
       "  0.906,\n",
       "  0.925,\n",
       "  0.882,\n",
       "  0.794,\n",
       "  0.826,\n",
       "  0.785,\n",
       "  0.42,\n",
       "  0.392,\n",
       "  0.43,\n",
       "  0.363,\n",
       "  0.17,\n",
       "  0.1,\n",
       "  0.123,\n",
       "  0.17,\n",
       "  0.177,\n",
       "  0.19,\n",
       "  0.218,\n",
       "  0.25,\n",
       "  0.374,\n",
       "  0.492,\n",
       "  0.638,\n",
       "  0.647,\n",
       "  0.48,\n",
       "  0.348,\n",
       "  0.277,\n",
       "  0.313,\n",
       "  0.269,\n",
       "  0.325,\n",
       "  0.346,\n",
       "  0.338,\n",
       "  0.303,\n",
       "  0.304,\n",
       "  0.317,\n",
       "  0.341,\n",
       "  0.326,\n",
       "  0.362,\n",
       "  0.344,\n",
       "  0.328,\n",
       "  0.323,\n",
       "  0.282,\n",
       "  0.286,\n",
       "  0.28,\n",
       "  0.267,\n",
       "  0.163,\n",
       "  0.15,\n",
       "  0.144,\n",
       "  0.13,\n",
       "  0.089,\n",
       "  0.074,\n",
       "  0.069,\n",
       "  0.089,\n",
       "  0.112,\n",
       "  0.158,\n",
       "  0.167,\n",
       "  0.183,\n",
       "  0.207,\n",
       "  0.251,\n",
       "  0.339,\n",
       "  0.377,\n",
       "  0.417,\n",
       "  0.414,\n",
       "  0.328,\n",
       "  0.291,\n",
       "  0.311,\n",
       "  0.329,\n",
       "  0.326,\n",
       "  0.211,\n",
       "  0.199,\n",
       "  0.188,\n",
       "  0.184,\n",
       "  0.183,\n",
       "  0.185,\n",
       "  0.159,\n",
       "  0.149,\n",
       "  0.174,\n",
       "  0.154,\n",
       "  0.175,\n",
       "  0.174,\n",
       "  0.18,\n",
       "  0.186,\n",
       "  0.262,\n",
       "  0.28,\n",
       "  0.281,\n",
       "  0.275,\n",
       "  0.306,\n",
       "  0.323,\n",
       "  0.314,\n",
       "  0.26,\n",
       "  0.293,\n",
       "  0.358,\n",
       "  0.358,\n",
       "  0.32,\n",
       "  0.217,\n",
       "  0.165,\n",
       "  0.228,\n",
       "  0.233,\n",
       "  0.211,\n",
       "  0.214,\n",
       "  0.215,\n",
       "  0.359,\n",
       "  0.54,\n",
       "  0.56,\n",
       "  0.615,\n",
       "  0.609,\n",
       "  0.605,\n",
       "  0.622,\n",
       "  0.601,\n",
       "  0.596,\n",
       "  0.476,\n",
       "  0.318,\n",
       "  0.198,\n",
       "  0.188,\n",
       "  0.173,\n",
       "  0.23,\n",
       "  0.263,\n",
       "  0.248,\n",
       "  0.295,\n",
       "  0.345,\n",
       "  0.373,\n",
       "  0.485,\n",
       "  0.574,\n",
       "  3.04,\n",
       "  3.293,\n",
       "  4.076,\n",
       "  4.092,\n",
       "  1.599,\n",
       "  1.667,\n",
       "  2.108,\n",
       "  2.65,\n",
       "  2.815,\n",
       "  2.685,\n",
       "  2.553,\n",
       "  2.424,\n",
       "  2.005,\n",
       "  1.762,\n",
       "  1.954,\n",
       "  1.217,\n",
       "  3.696,\n",
       "  2.985,\n",
       "  3.007,\n",
       "  2.849,\n",
       "  2.696,\n",
       "  2.16,\n",
       "  0.525,\n",
       "  0.638,\n",
       "  0.854,\n",
       "  0.89,\n",
       "  0.575,\n",
       "  0.355,\n",
       "  0.222,\n",
       "  0.158,\n",
       "  0.136,\n",
       "  0.147,\n",
       "  0.197,\n",
       "  0.414,\n",
       "  0.605,\n",
       "  0.738,\n",
       "  0.824,\n",
       "  0.852,\n",
       "  0.889,\n",
       "  1.022,\n",
       "  0.999,\n",
       "  1.034,\n",
       "  1.2,\n",
       "  1.07,\n",
       "  1.124,\n",
       "  1.034,\n",
       "  0.624,\n",
       "  0.69,\n",
       "  0.311,\n",
       "  0.341,\n",
       "  0.423,\n",
       "  0.441,\n",
       "  0.305,\n",
       "  0.305,\n",
       "  0.323,\n",
       "  0.5,\n",
       "  0.68,\n",
       "  0.611,\n",
       "  0.492,\n",
       "  0.381,\n",
       "  0.272,\n",
       "  0.257,\n",
       "  0.211,\n",
       "  0.19,\n",
       "  0.173,\n",
       "  0.141,\n",
       "  0.114,\n",
       "  0.078,\n",
       "  0.083,\n",
       "  0.107,\n",
       "  0.175,\n",
       "  0.219,\n",
       "  0.391,\n",
       "  0.635,\n",
       "  0.935,\n",
       "  1.497,\n",
       "  3.459,\n",
       "  5.007,\n",
       "  5.832,\n",
       "  5.559,\n",
       "  1.233,\n",
       "  0.355,\n",
       "  0.348,\n",
       "  0.025,\n",
       "  0.029,\n",
       "  0.018,\n",
       "  0.019,\n",
       "  0.02,\n",
       "  0.015,\n",
       "  0.011,\n",
       "  0.012,\n",
       "  0.017,\n",
       "  3.637,\n",
       "  3.198,\n",
       "  3.479,\n",
       "  2.905,\n",
       "  2.184,\n",
       "  1.078,\n",
       "  1.488,\n",
       "  0.809,\n",
       "  0.683,\n",
       "  0.477,\n",
       "  0.388,\n",
       "  0.103,\n",
       "  0.037,\n",
       "  0.04,\n",
       "  0.043,\n",
       "  0.039,\n",
       "  0.034,\n",
       "  0.034,\n",
       "  0.035,\n",
       "  0.036,\n",
       "  0.036,\n",
       "  0.031,\n",
       "  0.026,\n",
       "  0.031,\n",
       "  0.028,\n",
       "  0.028,\n",
       "  0.041,\n",
       "  0.042,\n",
       "  0.041,\n",
       "  0.038,\n",
       "  0.042,\n",
       "  0.037,\n",
       "  0.038,\n",
       "  0.041,\n",
       "  0.034,\n",
       "  0.035,\n",
       "  0.031,\n",
       "  0.032,\n",
       "  0.038,\n",
       "  0.041,\n",
       "  0.038,\n",
       "  0.035,\n",
       "  0.032,\n",
       "  0.033,\n",
       "  0.038,\n",
       "  0.042,\n",
       "  0.047,\n",
       "  0.057,\n",
       "  0.066,\n",
       "  0.075,\n",
       "  0.07,\n",
       "  0.063,\n",
       "  0.061,\n",
       "  0.035,\n",
       "  0.028,\n",
       "  0.029,\n",
       "  0.035,\n",
       "  0.036,\n",
       "  0.034,\n",
       "  0.03,\n",
       "  0.029,\n",
       "  0.03,\n",
       "  0.036,\n",
       "  0.042,\n",
       "  0.056,\n",
       "  0.091,\n",
       "  0.109,\n",
       "  0.117,\n",
       "  0.116,\n",
       "  0.124,\n",
       "  0.14,\n",
       "  0.141,\n",
       "  0.151,\n",
       "  0.197,\n",
       "  0.295,\n",
       "  0.295,\n",
       "  0.295,\n",
       "  0.295,\n",
       "  0.285,\n",
       "  0.263,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " '/home/vera/projects/masters_project/data/s-pred_features/embeddings_4kmu_a.pt')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8304 1038 1038\n",
      "torch.Size([1, 1, 164, 768])\n",
      "torch.Size([1, 1, 164, 288])\n",
      "164\n",
      "('/home/vera/projects/masters_project/data/s-pred_features/embeddings_5cuh_a.pt',)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train, validation and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "# Test if the dataset is split correctly\n",
    "print(len(train_dataset), len(valid_dataset), len(test_dataset))\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 1 \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Test if the dataloaders are working correctly\n",
    "for i, (features, maps, rmsds, feature_path) in enumerate(train_loader):\n",
    "    print(features.shape)\n",
    "    print(maps.shape)\n",
    "    print(len(rmsds))\n",
    "    print(feature_path)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m targets \u001b[39m=\u001b[39m [sample[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m train_dataset]\n\u001b[1;32m      2\u001b[0m sorted_targets, sorted_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(torch\u001b[39m.\u001b[39mtensor(targets))\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msorted_targets\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m targets \u001b[39m=\u001b[39m [sample[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m train_dataset]\n\u001b[1;32m      2\u001b[0m sorted_targets, sorted_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(torch\u001b[39m.\u001b[39mtensor(targets))\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msorted_targets\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     12\u001b[0m     feature_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39miloc[idx,\u001b[39m0\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m     embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(feature_path)\n\u001b[1;32m     14\u001b[0m     features \u001b[39m=\u001b[39m embeddings[:, :, :\u001b[39m768\u001b[39m]\n\u001b[1;32m     15\u001b[0m     maps \u001b[39m=\u001b[39m embeddings[:, :, \u001b[39m768\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:794\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    791\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    793\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m--> 794\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    795\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    797\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n\u001b[1;32m    799\u001b[0m         \u001b[39mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:80\u001b[0m, in \u001b[0;36m_is_zipfile\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     77\u001b[0m read_bytes \u001b[39m=\u001b[39m []\n\u001b[1;32m     78\u001b[0m start \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell()\n\u001b[0;32m---> 80\u001b[0m byte \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mread(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     81\u001b[0m \u001b[39mwhile\u001b[39;00m byte \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     82\u001b[0m     read_bytes\u001b[39m.\u001b[39mappend(byte)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Sort the data by length of the embeddings\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_dataset \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(train_dataset, key\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: x[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], reverse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Go through the data and create batches of embeddings with the same length\u001b[39;00m\n\u001b[1;32m      6\u001b[0m train_batches \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     12\u001b[0m     feature_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39miloc[idx,\u001b[39m0\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m     embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(feature_path)\n\u001b[1;32m     14\u001b[0m     features \u001b[39m=\u001b[39m embeddings[:, :, :\u001b[39m768\u001b[39m]\n\u001b[1;32m     15\u001b[0m     maps \u001b[39m=\u001b[39m embeddings[:, :, \u001b[39m768\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:811\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    810\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 811\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    812\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    813\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:1174\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1172\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1173\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1174\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1176\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1178\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:1144\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1143\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1144\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1146\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:1118\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1114\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[1;32m   1115\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1118\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1119\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1120\u001b[0m     _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1122\u001b[0m \u001b[39mif\u001b[39;00m typed_storage\u001b[39m.\u001b[39m_data_ptr() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1123\u001b[0m     loaded_storages[key] \u001b[39m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:219\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    218\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 219\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    220\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:184\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    183\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 184\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    185\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    186\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/serialization.py:167\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_cuda_device\u001b[39m(location):\n\u001b[1;32m    165\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mis_available():\n\u001b[1;32m    168\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    171\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    172\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    173\u001b[0m     device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n",
      "File \u001b[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/torch/cuda/__init__.py:116\u001b[0m, in \u001b[0;36mis_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m device_count() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[39m# The default availability inspection never throws and returns 0 if the driver is missing or can't\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39m# be initialized. This uses the CUDA Runtime API `cudaGetDeviceCount` which in turn initializes the CUDA Driver\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39m# API via `cuInit`\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_getDeviceCount() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "# Sort the data by length of the embeddings\n",
    "train_dataset = sorted(train_dataset, key=lambda x: x[0].shape[1], reverse=True)\n",
    "\n",
    "# Go through the data and create batches of embeddings with the same length\n",
    "train_batches = []\n",
    "\n",
    "for i in range(0, len(train_dataset), batch_size):\n",
    "    batch = train_dataset[i:i+batch_size]\n",
    "    # Check if all embeddings in the batch have the same length\n",
    "    if len(set([embedding[0].shape[1] for embedding in batch])) != 1:\n",
    "        continue\n",
    "    train_batches.append(batch)\n",
    "# Shuffle the batches\n",
    "random.shuffle(train_batches)\n",
    "\n",
    "# Test if the batches are created correctly\n",
    "for i, batch in enumerate(train_batches):\n",
    "    print('Batch ' + str(i))\n",
    "    for features, maps, rmsds, feature_path in batch:\n",
    "        print(features.shape)\n",
    "        print(maps.shape)\n",
    "        print(len(rmsds))\n",
    "        print(feature_path)\n",
    "    break\n",
    "\n",
    "# Create data loaders for the batches\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_batches)\n",
    "\n",
    "# Test if the dataloaders are working correctly\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print('Batch ' + str(i))\n",
    "    for features, maps, rmsds, feature_path in batch:\n",
    "        print(features.shape)\n",
    "        print(maps.shape)\n",
    "        print(len(rmsds))\n",
    "        print(feature_path)\n",
    "    break\n",
    "\n",
    "\n",
    "print(len(train_batches))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM model\n",
    "class lstm_net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_feature_size=768, hidden_node=256, dropout=0.25, class_num=8):\n",
    "        super(lstm_net, self).__init__()\n",
    "\n",
    "        self.linear_proj = nn.Sequential(\n",
    "            nn.Linear(input_feature_size, input_feature_size // 2),\n",
    "            nn.InstanceNorm1d(input_feature_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_feature_size // 2, input_feature_size // 4),\n",
    "            nn.InstanceNorm1d(input_feature_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_feature_size // 4, input_feature_size // 4),\n",
    "        )\n",
    "\n",
    "        lstm_input_feature_size = input_feature_size // 4 + 144*2\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_feature_size,\n",
    "            hidden_size=hidden_node,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.to_property = nn.Sequential(\n",
    "            nn.Linear(hidden_node * 2, hidden_node * 2),\n",
    "            nn.InstanceNorm1d(hidden_node * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_node * 2, class_num),\n",
    "        )\n",
    "\n",
    "    def forward(self, msa_query_embeddings, msa_attention_features):\n",
    "        msa_query_embeddings = self.linear_proj(msa_query_embeddings)\n",
    "\n",
    "        lstm_input = torch.cat([msa_query_embeddings, msa_attention_features], dim=2)\n",
    "        lstm_input = lstm_input.permute((1, 0, 2))\n",
    "\n",
    "        lstm_output, lstm_hidden = self.lstm(lstm_input)\n",
    "        lstm_output = lstm_output.permute((1, 0, 2))\n",
    "        \n",
    "        label_output = self.to_property(lstm_output)\n",
    "        #print(lstm_output)\n",
    "        #print(label_output)\n",
    "\n",
    "        return label_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m valid_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m i, (features, maps, rmsds, feature_path) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m---> 36\u001b[0m     features \u001b[39m=\u001b[39m features[\u001b[39m0\u001b[39;49m,:,:,:]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m     maps \u001b[39m=\u001b[39m maps[\u001b[39m0\u001b[39m,:,:,:]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     38\u001b[0m     labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39mint\u001b[39m(label \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m RMSD_THRESHOLD) \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m rmsds])\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0\n",
    "#WEIGHT_DECAY = 0.0001\n",
    "BATCH_SIZE = 1\n",
    "HIDDEN_NODE = 256\n",
    "DROPOUT = 0\n",
    "CLASS_NUM = 1\n",
    "NUM_ACCUMULATION_STEPS = 2\n",
    "\n",
    "RMSD_THRESHOLD = 1\n",
    "\n",
    "#train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "model = lstm_net(input_feature_size=768, hidden_node=HIDDEN_NODE, dropout=DROPOUT, class_num=CLASS_NUM)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.zero_grad()\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "\n",
    "    for i, (features, maps, rmsds, feature_path) in enumerate(train_loader):\n",
    "        features = features[0,:,:,:].to(device)\n",
    "        maps = maps[0,:,:,:].to(device)\n",
    "        labels = torch.Tensor([int(label >= RMSD_THRESHOLD) for label in rmsds]).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(msa_query_embeddings=features, msa_attention_features=maps)\n",
    "        loss = criterion(output[0,:,0], labels)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "    train_loss_list.append(train_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (features, maps, rmsds, feature_path) in enumerate(valid_loader):\n",
    "            features = features[0,:,:,:].to(device)\n",
    "            maps = maps[0,:,:,:].to(device)\n",
    "            labels = torch.Tensor([int(label >= RMSD_THRESHOLD) for label in rmsds]).to(device)\n",
    "\n",
    "            output = model(msa_query_embeddings=features, msa_attention_features=maps)\n",
    "            loss = criterion(output[0,:,0], labels)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "        valid_loss_list.append(valid_loss / len(valid_loader))\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss_list[-1], valid_loss_list[-1]))\n",
    "    \n",
    "    model.train()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_df = pd.read_csv('/home/vera/projects/masters_project/data/rmsd_dataset.csv')\n",
    "sequence_length_dict = {}\n",
    "for i in range(len(csv_file_df)):\n",
    "    sequence_length = len(literal_eval(csv_file_df.iloc[i,1]))\n",
    "    if sequence_length not in sequence_length_dict:\n",
    "        sequence_length_dict[sequence_length] = 1\n",
    "    else:\n",
    "        sequence_length_dict[sequence_length] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "THRESHOLD_1 = 12\n",
    "\n",
    "# Plot the sequence lengths from the dictionary using a histogram       \n",
    "plt.figure(figsize=(16,4))\n",
    "plt.bar(sequence_length_dict.keys(), sequence_length_dict.values(), color='black', width=1)\n",
    "colors = ['red', 'orange', 'yellow', 'green', 'blue', 'purple']\n",
    "for i in [6, 5, 4, 3, 2, 1]:\n",
    "        plt.bar([key for key in sequence_length_dict.keys() if sequence_length_dict[key] < THRESHOLD_1*i],\n",
    "                [sequence_length_dict[key] for key in sequence_length_dict.keys() if sequence_length_dict[key] < THRESHOLD_1*i],\n",
    "                color=colors[i-1], width=1)\n",
    "        plt.bar([key for key in sequence_length_dict.keys() if sequence_length_dict[key] >= THRESHOLD_1*i],\n",
    "                [THRESHOLD_1*i for key in sequence_length_dict.keys() if sequence_length_dict[key] >= THRESHOLD_1*i],\n",
    "                color=colors[i-1], width=1)\n",
    "\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sequence Lengths of the RMSD Dataset')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SE3-nvidia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
