{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a563d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f4674456310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import squareform, pdist, cdist\n",
    "from Bio import SeqIO\n",
    "import pickle\n",
    "from time import sleep\n",
    "import esm\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b31610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an efficient way to delete lowercase characters and insertion characters from a string\n",
    "deletekeys = dict.fromkeys(string.ascii_lowercase)\n",
    "deletekeys[\".\"] = None\n",
    "deletekeys[\"*\"] = None\n",
    "translation = str.maketrans(deletekeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bef52dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_insertions(sequence: str) -> str:\n",
    "    \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n",
    "    return sequence.translate(translation)\n",
    "\n",
    "def read_msa(filename: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\" Reads the sequences from an MSA file, automatically removes insertions.\"\"\"\n",
    "    return [(record.description, remove_insertions(str(record.seq))) for record in SeqIO.parse(filename, \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f113d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sequences from the MSA to maximize the hamming distance\n",
    "# Alternatively, can use hhfilter\n",
    "def greedy_select(msa: List[Tuple[str, str]], num_seqs: int, mode: str = \"max\") -> List[Tuple[str, str]]:\n",
    "    assert mode in (\"max\", \"min\")\n",
    "    if len(msa) <= num_seqs:\n",
    "        return msa\n",
    "\n",
    "    array = np.array([list(seq) for _, seq in msa], dtype=np.bytes_).view(np.uint8)\n",
    "\n",
    "    optfunc = np.argmax if mode == \"max\" else np.argmin\n",
    "    all_indices = np.arange(len(msa))\n",
    "    indices = [0]\n",
    "    pairwise_distances = np.zeros((0, len(msa)))\n",
    "    for _ in range(num_seqs - 1):\n",
    "        dist = cdist(array[indices[-1:]], array, \"hamming\")\n",
    "        pairwise_distances = np.concatenate([pairwise_distances, dist])\n",
    "        shifted_distance = np.delete(pairwise_distances, indices, axis=1).mean(0)\n",
    "        shifted_index = optfunc(shifted_distance)\n",
    "        index = np.delete(all_indices, indices)[shifted_index]\n",
    "        indices.append(index)\n",
    "    indices = sorted(indices)\n",
    "    return [msa[idx] for idx in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411a86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(pdb_ids, msas_pickle=False):\n",
    "    \"\"\"Creates a pt file containing the embeddings for each pdb ID in the input.\"\"\"\n",
    "\n",
    "    torch.cuda.set_device(1)\n",
    "\n",
    "    if msas_pickle == False:\n",
    "        msas = {}\n",
    "        for name in pdb_ids:\n",
    "            msa_path = \"../data/alignments/aligned_\" + name.lower() + \".a3m\"\n",
    "            if os.path.isfile(msa_path):\n",
    "                msas[name] = read_msa(msa_path)\n",
    "    else:\n",
    "        with open(msas_pickle, 'rb') as unpickled_msas:\n",
    "            msas = pickle.load(unpickled_msas)\n",
    "\n",
    "    msa_transformer, msa_transformer_alphabet = esm.pretrained.esm_msa1b_t12_100M_UR50S()\n",
    "    msa_transformer = msa_transformer.eval().cuda()\n",
    "    msa_transformer_batch_converter = msa_transformer_alphabet.get_batch_converter()\n",
    "\n",
    "    for name in pdb_ids:\n",
    "        try:\n",
    "            inputs = msas[name]\n",
    "            inputs = greedy_select(inputs, num_seqs=512)\n",
    "            msa_transformer_batch_labels, msa_transformer_batch_strs, msa_transformer_batch_tokens = msa_transformer_batch_converter([inputs])\n",
    "            msa_transformer_batch_tokens = msa_transformer_batch_tokens.to(next(msa_transformer.parameters()).device)\n",
    "            with torch.no_grad():\n",
    "                result = msa_transformer(msa_transformer_batch_tokens, repr_layers=[12])\n",
    "            embeddings = result[\"representations\"][12]\n",
    "            torch.save(embeddings, '../data/embeddings/embeddings_' + name + '.pt')\n",
    "        except BaseException as e:\n",
    "            print(\"Couldn't create embeddings for \" + name)\n",
    "            print(e)\n",
    "            torch.cuda.empty_cache()\n",
    "            sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cfcc018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide some pdb IDs in the format '1abc_a'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "IPython won't let you open fd=False by default as it is likely to crash IPython. If you know what you are doing, you can use builtins' open.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(msa_pkl) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     12\u001B[0m     msa_pkl \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mFalse\u001B[39;00m]\n\u001B[0;32m---> 14\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpdbs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsas_pickle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmsa_pkl\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[5], line 13\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(pdb_ids, msas_pickle)\u001B[0m\n\u001B[1;32m     11\u001B[0m             msas[name] \u001B[38;5;241m=\u001B[39m read_msa(msa_path)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 13\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmsas_pickle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m unpickled_msas:\n\u001B[1;32m     14\u001B[0m         msas \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(unpickled_msas)\n\u001B[1;32m     16\u001B[0m msa_transformer, msa_transformer_alphabet \u001B[38;5;241m=\u001B[39m esm\u001B[38;5;241m.\u001B[39mpretrained\u001B[38;5;241m.\u001B[39mesm_msa1b_t12_100M_UR50S()\n",
      "File \u001B[0;32m~/miniconda3/envs/SE3-nvidia/lib/python3.9/site-packages/IPython/core/interactiveshell.py:276\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(io_open)\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_modified_open\u001B[39m(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    275\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m--> 276\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    277\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    279\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    280\u001B[0m         )\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;31mValueError\u001B[0m: IPython won't let you open fd=False by default as it is likely to crash IPython. If you know what you are doing, you can use builtins' open."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    arguments = sys.argv[1:]\n",
    "    if type(arguments[0]) == list:\n",
    "        pdbs = [pdb for pdb in arguments[0] if len(pdb) == 6]\n",
    "    else:\n",
    "        pdbs = [arg for arg in arguments if len(arg) == 6]\n",
    "    if len(pdbs) == 0:\n",
    "        print(\"Please provide some pdb IDs in the format '1abc_a'\")\n",
    "\n",
    "    msa_pkl = [arg for arg in arguments if arg.endswith('.pkl')]\n",
    "    if len(msa_pkl) == 0:\n",
    "        msa_pkl = [False]\n",
    "\n",
    "    main(pdbs, msas_pickle=msa_pkl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca7c119f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1um_b\n",
      "'1um_b'\n"
     ]
    }
   ],
   "source": [
    "main(['1um_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e690f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a19ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c3d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec64c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
